# TrustMed AI – Symptom Intake Prototype

This is a prototype for **TrustMed AI**, a mobile-friendly web app that explores how an AI assistant can help patients **structure their symptom information** before a visit with a clinician.

The focus of this project is on:

- **Guided symptom intake** (step-by-step flow)  
- **LLM-assisted structuring** of free-text concerns  
- **Risk scoring logic in code** (not done by the model)  
- **Questions to ask a clinician**, generated by an LLM  
It is **not** a diagnostic tool and is not intended for real medical use.

---
## 1. High-Level Overview

The prototype has two main pieces:

1. **Front-end (React Native / Expo web app)**  
   - Mobile-style UI with tabs (`Home`, `Explore`, `Resources`, `Profile`)  
   - The main research piece is the **“Health Consultation”** flow on the chatbot/intake screen in the `Explore` page.
2. **Back-end (Node + Express server)**  
   - Exposes three endpoints under `/v1/intake/...`  
   - Uses the OpenAI API to:
     - Classify and summarize concerns
     - Rewrite a risk assessment into patient-facing language
     - Generate suggested questions to ask a clinician

The **goal** is to show how a patient’s **free text** can be turned into a more structured, clinician-friendly summary, while still keeping safety constraints around what the model is allowed to say.

---
## 2. Front-End: Expo App
### Tech

- **React Native with Expo**
- Uses **ThemedView** and **ThemedText** components for light/dark theme support
- Bottom tab navigation via `expo-router`

### Important Screens

- `app/(tabs)/index.tsx`  
  Landing / Home screen.  
  - Introduces **TrustMed AI – Safer Symptom Intake**
  - Main CTA is “Start Symptom Check”, which links into the intake flow.
  - Other tabs (Resources, Profile) are simple mockups for app structure only.

- `app/(tabs)/explore.tsx`
  **Main research screen – “Health Consultation”**.  
  This screen implements the **4-step intake flow**:

  1. **Free-text input**  
     - The user describes what’s going on in their own words.  
     - On “Analyze Symptoms”, the app calls the backend `/v1/intake/concern-analyze`.  
     - The backend returns:
       - `primaryCategory`
       - `candidateCategories[]`
       - `clinicalSummary`

  2. **Concern selection**  
     - The user picks the concern label that best matches their situation.  
     - The app maps this label to a **list of symptoms** for the next step.

  3. **Symptom sliders**  
     - For each symptom, the user rates severity from **None → Severe (0–3)** using sliders.  
     - This data is purely in-app at this point.

  4. **Risk assessment + questions**  
     - The app runs a **deterministic risk-scoring function** in TypeScript.
     - It then calls `/v1/intake/final-report` so the LLM can rewrite the summary and analysis.
     - It also calls `/v1/intake/generate-questions` to generate **questions the patient can ask a clinician**.
     - Step 4 shows:
       - Risk level (Low / Moderate / High)
       - Summary and analysis
       - Recommendations
       - Questions to ask your clinician
       - Disclaimer

### UI Helper Components

These are mostly for styling and layout — they **do not** contain any clinical or AI logic:

- `components/themed-view.tsx`  
  Reusable container that adapts background color to light/dark mode.

- `components/themed-text.tsx`  
  Reusable text component with presets (`title`, `subtitle`, etc.) and theme-aware colors.

- `components/nav.tsx`  
  Simple sticky header that displays the **TrustMed** logo at the top of the screen.

- `app/(tabs)/resources.tsx`, `app/(tabs)/profile.tsx`  
  Mockup pages for navigation structure. No backend or AI integration.

---

## 3. Back-End: Node + Express + OpenAI

The backend lives in a separate folder (e.g. `trustmed-backend`) and is started via **`index.mjs`**.

### Tech

- Node.js + Express
- CORS enabled
- Uses `dotenv` to load `OPENAI_API_KEY`
- Calls OpenAI’s `/v1/chat/completions` API with **structured system prompts**

### Environment Variables

Create a `.env` file in the backend folder with:

```bash
OPENAI_API_KEY=your_openai_key_here
PORT=3000

For security reasons API keys cannot be shared.
The backend requires the instructor to add their own OpenAI API key in a .env file.
I included instructions in the README.